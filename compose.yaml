services:
  speaches:
    container_name: speaches
    # NOTE: slightly older cuda version is available under 'latest-cuda-12.4.1' and `latest-cuda-12.6.3` tags
    image: ghcr.io/speaches-ai/speaches:latest-cuda-12.6.3
    build:
      dockerfile: Dockerfile
      context: .
      platforms:
        - linux/amd64
        - linux/arm64
      args:
        BASE_IMAGE: nvidia/cuda:12.9.0-cudnn-runtime-ubuntu24.04
    restart: unless-stopped
    ports:
      - 8000:8000
    develop:
      watch:
        - action: rebuild
          path: ./uv.lock
        - action: sync+restart
          path: ./src
          target: /home/ubuntu/speaches/src
    env_file:
      - path: .env
        required: false
    volumes:
      - hf-hub-cache:/home/ubuntu/.cache/huggingface/hub
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://0.0.0.0:8000/health"] # TODO: won't work if a user changes the port
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 5s
volumes:
  hf-hub-cache:
